# Matchminer Admin

This application provides automated processing of patient clinical, genomic, and trial data JSON files for the Matchminer system. It runs as a background data processor that executes on a configured schedule, processing all available files and sending the data to the Matchminer platform via API requests.

## Overview

The system processes JSON files from two main sources:

- **Patient Data JSON Files**: Generated by the [matchminer-patient](https://github.com/sumedhasaxena/matchminer-patient) repository, which provides a web interface for Clinical Data Analysts to enter, review, and submit patient data
- **Trial Data JSON Files**: Generated by the [nct2ctml](https://github.com/sumedhasaxena/nct2ctml) repository or manually curated trial files

The system can run continuously in the background without requiring service management.

---

## 1. Development Environment Setup

To get started with development, you'll need to set up an isolated Python environment. This prevents dependency conflicts with other projects. You can use either Python's built-in `venv` module or `conda`.

**Prerequisites:**
*   Git
*   Python 3.12
*   Anaconda or Miniconda (if using `conda`)

**Steps:**

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/sumedhasaxena/matchminer-admin.git
    cd matchminer-admin
    ```

2.  **Create and activate the environment:**

    Choose one of the following options:

    **Option A: Using `venv` (standard Python)**

    a. **Create the virtual environment:**
    *   On **macOS and Linux**:
        ```bash
        python -m venv venv
        ```
    *   On **Windows**:
        ```bash
        python -m venv venv
        ```

    b. **Activate the virtual environment:**
    *   On **macOS and Linux**:
        ```bash
        source venv/bin/activate
        ```
    *   On **Windows**:
        ```bash
        .\venv\Scripts\activate
        ```
    ---
    **Option B: Using `conda`**

    a. **Create the Conda environment:**
    ```bash
    conda create --name matchminer-admin-env python=3.12
    ```
    *(You can replace `matchminer-admin-env` with your preferred environment name.)*

    b. **Activate the Conda environment:**
    ```bash
    conda activate matchminer-admin-env
    ```

Your terminal prompt should now be prefixed with `(venv)` or `(matchminer-admin-env)`, indicating that the environment is active.

---

## 2. Installing Dependencies

All the required Python packages are listed in the `requirements.txt` file.

With your environment activated, run the following command to install them:

```bash
pip install -r requirements.txt
```

---

## 3. Configuration Setup

Before running the application, you need to configure the Matchminer server connection details.

1.  **Edit the configuration file:**
    ```bash
    nano config.py
    ```

2.  **Set config details:**
    ```python
    # Matchminer server configuration
    MATCHMINER_SERVER = "https://your-matchminer-server.com/"
    TOKEN = "your-authentication-token"
    
    # Data processor configuration
WATCHER_INTERVAL_MINUTES = 120  # Process files every 120 minutes (2 hours)
    
    # Patient data paths
    PATIENT_DATA_BASE_DIR = "path/to/matchminer-patient"  # Root directory of MATCHMINER_PATIENT repository
    PATIENT_FOLDER = os.path.join(PATIENT_DATA_BASE_DIR, "patient_data_reviewed")
    PATIENT_CLINICAL_JSON_FOLDER = "clinical"
    PATIENT_GENOMIC_JSON_FOLDER = "genomic"
    
    # Trial data paths
    TRIAL_DATA_BASE_DIR = "path/to/nct2ctml"  # Root directory of NCT2CTML repository
    TRIAL_FOLDER = os.path.join(TRIAL_DATA_BASE_DIR, "trial_data_reviewed")
    
    # Processed data folders (usually don't need to change these)
    TRIAL_JSON_PROCESSED_FOLDER = "trial_data_processed"
    PATIENT_JSON_PROCESSED_FOLDER = "patient_data_processed"
    ```

**Note:** If you're setting up for the first time, you may also need to configure the trial environment settings. See the **Configuration Files** section below for details on `matchminer_trial_data_env_config.json`.

---

## 4. Running the Application Locally

Once the setup is complete and the dependencies are installed, you can run the file processor in different modes.

### **A. Test Mode (Single Run)**

To test the system with existing files:

```bash
python data_processor.py --once
```

This will process all available files once and exit, allowing you to verify everything works correctly.

### **B. Development Mode (Foreground)**

To run the data processor in the foreground (you'll see all output):

```bash
# Use interval from config.py
python data_processor.py

# Override with custom interval in minutes (e.g., 240 minutes = 4 hours)
python data_processor.py --minutes 240

```

This will:
- Process files at the configured interval
- Show all processing messages in the terminal
- Stop when you press Ctrl+C

### **C. Manual Operations**

#### **Trial Operations:**
```bash
# Insert all trials from JSON files
python trial.py insert

# Get trial by protocol number
python trial.py get --protocol_no 2024060101

# Update trial by protocol number
python trial.py update --protocol_no 2024060101 --updated_trial_file updated_trial.json

# Get max protocol_id and protocol_no from all trials.
# The might be helpful to reset the protocol id and number in matchminer_trial_data_env_config.json
python trial.py get_max_pid_pno

# Get all NCT IDs from all trials
python trial.py get_all_nct_ids
```

#### **Patient Operations:**
```bash
# Process all patient clinical and genomic data
python patient.py
```

#### **Data Processor Operations:**
```bash
# Process all files once (test mode)
python data_processor.py --once

# Run data processor with default interval from config.py
python data_processor.py

# Run data processor with custom interval in minutes
python data_processor.py --minutes 240
```

---

## 5. Application Flow

The data processor follows a simple, automated workflow:

1.  **File Processing:** The system processes all available JSON files from the `patient_data_reviewed/clinical`, `patient_data_reviewed/genomic`, and `trial_data_reviewed` directories.
2.  **Processing Trigger:** Every 2 hours (configurable), the system automatically processes all files.
3.  **Data Processing:** For each file type:
    - **Patient Clinical Data:** Processes clinical information and sends to Matchminer
    - **Patient Genomic Data:** Processes genomic information and sends to Matchminer
    - **Trial Data:** Processes trial information with auto-incrementing protocol IDs and sends to Matchminer
4.  **File Management:** Successfully processed files are moved to `patient_data_processed/` and `trial_data_processed/` directories.
5.  **Logging:** All activities are logged to `processor.log` with timestamps and error details.

---

## 6. Deployment (Production on Linux)

To deploy this application to a production Linux server, we use the `start_processor.sh` script which runs the data processor in the background with nohup.

### **A. Setup Instructions:**

1.  **Clone the Repository:**
    ```bash
    git clone https://github.com/sumedhasaxena/matchminer-admin.git
    cd matchminer-admin
    ```

2.  **Set Up Environment:** Create and activate a Python virtual environment as described in the setup section.

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure the Application:** Edit `config.py` with your production Matchminer server details.

5.  **Test the Setup:**
    ```bash
    python file_watcher.py --once
    ```

### **B. Deploy to Production:**

1.  **Make the startup script executable:**
    ```bash
    chmod +x start_processor.sh
    ```

2.  **Start the data processor in production:**
    ```bash
    ./start_processor.sh
    ```

    This will:
    - Run all dependency and configuration checks
    - Start the data processor in the background using nohup
    - Show you the process ID and management commands
    - Continue running even after you close the terminal

### **C. Verify Deployment:**

1.  **Check if the process is running:**
    ```bash
    ps aux | grep data_processor.py
    ```

2.  **View application logs:**
    ```bash
    tail -f processor.log
    ```

3.  **Test file processing:** Place a test JSON file in one of the monitored directories and check if it gets processed.

### **D. Management Commands:**

**Stop the data processor:**
```bash
pkill -f data_processor.py
```

**Restart the data processor:**
```bash
# Stop the current process
pkill -f data_processor.py

# Start a new instance
./start_processor.sh
```

**Monitor logs in real-time:**
```bash
tail -f processor.log
```

---

## 7. Troubleshooting & Additional Setup

### **A. Common Issues**

**Permission Denied:**
```bash
# Make startup script executable
chmod +x start_processor.sh
```

**Missing Dependencies:**
```bash
# Install required packages
pip install -r requirements.txt
```

**Configuration Errors:**
- Check `config.py` for correct server URL and token
- Verify the Matchminer server is accessible

### **B. Logging and Monitoring**

**View Application Logs:**
```bash
# Real-time log monitoring
tail -f processor.log
```

**Check Process Status:**
```bash
# Check if data processor is running
ps aux | grep data_processor.py

# Check process details
ps -ef | grep data_processor.py
```

### **C. Configuration Files**

**Trial Environment Configuration (`matchminer_trial_data_env_config.json`):**
```json
{
    "protocol_id_counter": 1000,
    "protocol_no_counter": "01",
    "current_date": "20250108"
}
```

This file is automatically managed by the system and contains auto-incrementing counters for trial protocol IDs and numbers. When trials are inserted, protocol IDs and numbers are auto-generated as increments over the latest values in the Matchminer database.

**Configuration Management:**
To prevent conflicts with existing values in the database, the system retrieves the maximum protocol_id from the Matchminer database and sets the configuration counter to `max_protocol_id + 1`. As trials are inserted, the system automatically updates this configuration file to maintain the correct sequence.

The entries are used as follows:

- **`protocol_id_counter`**: Sets the next available protocol_id value. To reset this counter, use `python trial.py get_max_pid_pno` to get the maximum protocol_id from the system, then set this value to `max_pid + 1` in the config file.

- **`current_date`**: Used to format the protocol_number which is auto-generated. The system uses this date to create protocol numbers in the format `YYYYMMDD + counter`. When setting up for the first time, you can leave `current_date` as blank or set to `null`. The system will automatically set thee value when it runs for the first time.

- **`protocol_no_counter`**: The counter that gets appended to the current date to create the full protocol_number. This counter resets to "00" when the date changes. When setting up for the first time, you can leave `protocol_no_counter` to `00`. The system will automatically set the value when it runs for the first time.

**Example workflow:**
1. Run `python trial.py get_max_pid_pno` to get the current maximum protocol_id (e.g., 1050)
2. Set `protocol_id_counter` to 1051 in the config file
3. The system will automatically increment this counter for each new trial inserted
4. Protocol numbers will be generated as `20250108 + counter` (e.g., 2025010801, 2025010802, etc.)

**Main Configuration (`config.py`):**
- `MATCHMINER_SERVER`: Your Matchminer server URL
- `TOKEN`: Authentication token for API access
- `PATIENT_FOLDER`: Directory for patient data files
- `TRIAL_JSON_FOLDER`: Directory for trial data files
- `WATCHER_INTERVAL_MINUTES`: Interval in minutes for processing files (default: 120 = 2 hours)
